{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aritrasen87/LLM/blob/main/LLama3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gb06kXH_I2Fh"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "os.environ[\"HF_TOKEN\"] = userdata.get('HF_TOKEN')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wqxOxSxMQD2",
        "outputId": "40238c18-e592-4b90-c1d9-5af7588a21e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip -q install git+https://github.com/huggingface/transformers # need to install from github\n",
        "!pip -q install bitsandbytes accelerate xformers einops\n",
        "!pip -q install hf_transfer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Markdown, display"
      ],
      "metadata": {
        "id": "gHVmzfkEbuuE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2-KpRY-b25f",
        "outputId": "e205b69f-c332-47c7-e6b5-9fa6e6a6b45e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Apr 20 03:41:18 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import transformers\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM , BitsAndBytesConfig"
      ],
      "metadata": {
        "id": "2bEc2sovb7bL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import textwrap\n",
        "\n",
        "def wrap_text(text, width=90): #preserve_newlines\n",
        "    # Split the input text into lines based on newline characters\n",
        "    lines = text.split('\\n')\n",
        "\n",
        "    # Wrap each line individually\n",
        "    wrapped_lines = [textwrap.fill(line, width=width) for line in lines]\n",
        "\n",
        "    # Join the wrapped lines back together using newline characters\n",
        "    wrapped_text = '\\n'.join(wrapped_lines)\n",
        "\n",
        "    return wrapped_text"
      ],
      "metadata": {
        "id": "UOubBOXRfUv0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import pipeline\n",
        "\n",
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=\"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
        "    model_kwargs={\"torch_dtype\": torch.bfloat16,\n",
        "                  \"quantization_config\": {\"load_in_4bit\" : True},\n",
        "                  \"low_cpu_mem_usage\": True},\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "1e814b590afe496a8d66bd3253937477",
            "eedca9935aca44cc99b3509067290387",
            "c34b697a79fb4f1eb8d2ac27bd1c2bf8",
            "480ec5c7eda44a3faba692342b3a56a0",
            "e5594ec974fb4c85b47332c8eb254267",
            "ec3a7b57fd4246989c5839a14d8d39cf",
            "30d09236b59546d1997503131eeb65ec",
            "4a1735d06a66418db64a32c56b019ec1",
            "865876b70a1148d89e7313d62908bef6",
            "1266a07b15a149c9ae0b2bc32e9c1069",
            "25d3e173dc54428589a10b10c1e575bb"
          ]
        },
        "id": "BsIV5D2lfszI",
        "outputId": "607ce3f4-7e6d-465f-da1f-aaf62c7f876e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1e814b590afe496a8d66bd3253937477"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "cK9tEIZBIVDx"
      },
      "outputs": [],
      "source": [
        "def generate(input_text, system_prompt=\"\",max_length=512):\n",
        "    if system_prompt != \"\":\n",
        "        system_prompt = system_prompt\n",
        "    else:\n",
        "        system_prompt = \"You are a friendly and helpful assistant\"\n",
        "    messages = [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": system_prompt,\n",
        "        },\n",
        "        {\"role\": \"user\", \"content\": input_text},\n",
        "    ]\n",
        "\n",
        "    prompt = pipe.tokenizer.apply_chat_template(\n",
        "        messages,\n",
        "        tokenize=False,\n",
        "        add_generation_prompt=True\n",
        "            )\n",
        "    terminators = [\n",
        "        pipe.tokenizer.eos_token_id,\n",
        "        pipe.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
        "    ]\n",
        "\n",
        "    outputs = pipe(\n",
        "        prompt,\n",
        "        max_new_tokens=max_length,\n",
        "        eos_token_id=terminators,\n",
        "        do_sample=False,\n",
        "        temperature=0.0,\n",
        "        top_p=0.9,\n",
        "    )\n",
        "\n",
        "    generated_outputs = outputs[0][\"generated_text\"]\n",
        "    text = outputs[0][\"generated_text\"][len(prompt):]\n",
        "    wrapped_text = wrap_text(text)\n",
        "    display(Markdown(wrapped_text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 700
        },
        "id": "_jGa6FR-N-Ls",
        "outputId": "fbbfe27a-ab96-4078-9d1c-9cb001435f08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:497: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "What a wonderful question! As a Spiritual assistant, I'd be delighted to help you explore\nthe connection between Yoga and Spirituality. Here's a step-by-step analogy to help you\nunderstand the relationship between these two practices:\n\n**Step 1: Understanding Yoga**\n\nYoga is a physical, mental, and spiritual practice that originated in ancient India. It\ninvolves various postures (asanas), breathing techniques (pranayama), and meditation to\nunite the body, mind, and spirit. Yoga aims to balance the body's energy, calm the mind,\nand connect with the inner self.\n\n**Step 2: Understanding Spirituality**\n\nSpirituality is a personal and subjective experience that connects us to a higher power,\nthe universe, or a deeper sense of purpose. It's a journey to understand our place in the\nworld, our values, and our values. Spirituality can be practiced through various means,\nsuch as meditation, prayer, or simply being present in nature.\n\n**Step 3: The Connection between Yoga and Spirituality**\n\nNow, let's explore the connection between Yoga and Spirituality. Just as Yoga aims to\nunite the body, mind, and spirit, Spirituality seeks to connect us with a higher power or\na deeper sense of purpose. Both practices share a common goal: to find inner peace,\nbalance, and harmony.\n\n**Analogy: The Body, Mind, and Spirit**\n\nImagine the body as a physical temple, the mind as a mental sanctuary, and the spirit as a\nsacred inner space. Just as Yoga practices help to balance and harmonize the body and\nmind, Spirituality practices help to connect and align the body, mind, and spirit.\n\n**Step 4: The Practice of Yoga as a Spiritual Practice**\n\nWhen we practice Yoga, we're not just stretching our bodies or calming our minds; we're\nalso cultivating awareness, focus, and inner peace. These qualities are essential for\nspiritual growth and connection. As we move through Yoga postures, we're not just\nexercising our physical bodies; we're also awakening our inner selves.\n\n**Step 5: The Connection to the Divine**\n\nIn Yoga, we often connect with the divine through the practice of meditation, pranayama,\nor simply being present in the moment. This connection to the divine is a fundamental\naspect of Spirituality. As we practice Yoga, we're not just connecting with our inner\nselves; we're also connecting with the universe, the higher power, or the divine.\n\n**Conclusion**\n\nIn conclusion, Yoga and Spirituality are interconnected practices that share a common\ngoal: to find inner peace, balance, and harmony. Yoga practices help to balance the body\nand mind, while Spirituality practices help to connect us with a higher power or a deeper\nsense of purpose. By combining these practices, we can cultivate a deeper understanding of\nourselves and the world around us.\n\nI hope this analogy has helped you understand the connection between Yoga and\nSpirituality!"
          },
          "metadata": {}
        }
      ],
      "source": [
        "generate('Write a detailed analogy between Yoga and a Spirituality.',\n",
        "         system_prompt=\"You are a helpful Spiritual assistant. Write out your reasoning step-by-step to be sure you get the right answers!\",\n",
        "         max_length=1024)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate('Write a detailed history of LLM models.',\n",
        "         system_prompt=\"You are a helpful assistant. Write out your reasoning step-by-step to be sure you get the right answers!\",\n",
        "         max_length=1024)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 999
        },
        "id": "8RP17EoOfZ7A",
        "outputId": "9a377376-e1f0-4580-f982-b46248be9679"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Here's a detailed history of Large Language Models (LLMs) and their evolution over the\nyears:\n\n**Early Years (1950s-1980s)**\n\nThe concept of language processing and machine learning dates back to the 1950s. The first\nlanguage processing program, called the \"Logical Theorist,\" was developed by Allen Newell\nand Herbert Simon in 1956. This program was designed to simulate human problem-solving\nabilities by using logical reasoning and symbolic manipulation.\n\nIn the 1960s and 1970s, the development of the first artificial intelligence (AI)\nlanguages, such as Lisp and Prolog, laid the foundation for modern language processing.\nThese languages were designed to enable computers to reason and solve problems using\nlogical rules and semantic networks.\n\n**Rule-Based Systems (1980s-1990s)**\n\nThe 1980s and 1990s saw the development of rule-based systems, which were designed to\nmimic human language processing. These systems used hand-coded rules to analyze and\ngenerate language, but they were limited by their rigidity and inability to generalize.\n\nOne notable example of a rule-based system is the \"Hearsay\" system, developed in the 1980s\nby researchers at the University of California, Berkeley. Hearsay was designed to analyze\nand generate natural language text, but it relied heavily on hand-coded rules and was not\nable to learn from experience.\n\n**Statistical Language Processing (1990s-2000s)**\n\nThe 1990s and 2000s saw the development of statistical language processing techniques,\nwhich used machine learning algorithms to analyze and generate language. These techniques\nwere more flexible and able to learn from large datasets, but they were still limited by\ntheir reliance on hand-coded features and lack of contextual understanding.\n\nOne notable example of a statistical language processing system is the \"IBM Watson\"\nsystem, developed in the 1990s by IBM researchers. Watson was designed to analyze and\ngenerate natural language text, but it relied heavily on hand-coded features and was not\nable to learn from experience.\n\n**Deep Learning and Neural Networks (2000s-2010s)**\n\nThe 2000s and 2010s saw the development of deep learning and neural networks, which\nrevolutionized the field of language processing. These techniques used large datasets and\ncomplex neural networks to learn patterns and relationships in language, enabling machines\nto understand and generate language with unprecedented accuracy.\n\nOne notable example of a deep learning-based language model is the \"Word2Vec\" model,\ndeveloped in the 2010s by researchers at Google. Word2Vec used a neural network to learn\nword embeddings, which enabled machines to understand the relationships between words and\ngenerate language that was more natural and human-like.\n\n**Large Language Models (2010s-present)**\n\nThe 2010s saw the development of large language models (LLMs), which used massive datasets\nand complex neural networks to learn patterns and relationships in language. These models\nwere designed to be more accurate and flexible than earlier language models, and they have\nenabled machines to understand and generate language with unprecedented accuracy.\n\nOne notable example of an LLM is the \"BERT\" model, developed in 2018 by researchers at\nGoogle. BERT used a neural network to learn language patterns and relationships, and it\nwas trained on a massive dataset of text from the internet. BERT has been used to improve\nthe accuracy of language processing tasks, such as question answering and text\nclassification.\n\n**Recent Advances (2020s)**\n\nIn recent years, LLMs have continued to evolve and improve, with advances in areas such\nas:\n\n* **Multitask learning**: LLMs can be trained on multiple tasks simultaneously, enabling\nthem to learn more generalizable and transferable knowledge.\n* **Transfer learning**: LLMs can be fine-tuned on specific tasks or datasets, enabling\nthem to adapt to new domains and tasks.\n* **Explainability**: LLMs can be designed to provide explanations for their predictions\nand decisions, enabling humans to understand and trust the output of the model.\n\nSome notable recent advances in LLMs include:\n\n* **RoBERTa**: Developed in 2019, RoBERTa is a variant of the BERT model that uses a\ndifferent training approach and has achieved state-of-the-art results on many language\nprocessing tasks.\n* **DistilBERT**: Developed in 2020, DistilBERT is a smaller and more efficient version of\nthe BERT model that has achieved similar results on many language processing tasks.\n* **Longformer**: Developed in 2020, Longformer is a variant of the BERT model that is\ndesigned to handle longer sequences of text and has achieved state-of-the-art results on\nmany language processing tasks.\n\nOverall, the development of LLMs has revolutionized the field of language processing,\nenabling machines to understand and generate language with unprecedented accuracy and\nflexibility."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6rWuQb6anTpL"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyP+zxDbAy/1jEC46ufr4mM/",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1e814b590afe496a8d66bd3253937477": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eedca9935aca44cc99b3509067290387",
              "IPY_MODEL_c34b697a79fb4f1eb8d2ac27bd1c2bf8",
              "IPY_MODEL_480ec5c7eda44a3faba692342b3a56a0"
            ],
            "layout": "IPY_MODEL_e5594ec974fb4c85b47332c8eb254267"
          }
        },
        "eedca9935aca44cc99b3509067290387": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec3a7b57fd4246989c5839a14d8d39cf",
            "placeholder": "​",
            "style": "IPY_MODEL_30d09236b59546d1997503131eeb65ec",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "c34b697a79fb4f1eb8d2ac27bd1c2bf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a1735d06a66418db64a32c56b019ec1",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_865876b70a1148d89e7313d62908bef6",
            "value": 4
          }
        },
        "480ec5c7eda44a3faba692342b3a56a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1266a07b15a149c9ae0b2bc32e9c1069",
            "placeholder": "​",
            "style": "IPY_MODEL_25d3e173dc54428589a10b10c1e575bb",
            "value": " 4/4 [01:08&lt;00:00, 14.83s/it]"
          }
        },
        "e5594ec974fb4c85b47332c8eb254267": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec3a7b57fd4246989c5839a14d8d39cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30d09236b59546d1997503131eeb65ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4a1735d06a66418db64a32c56b019ec1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "865876b70a1148d89e7313d62908bef6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1266a07b15a149c9ae0b2bc32e9c1069": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25d3e173dc54428589a10b10c1e575bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}